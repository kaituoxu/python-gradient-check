{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use python 2.7\n",
    "# This notebook is based on cs231n/2016winter/assignment3\n",
    "# A bit of setup\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from rnn_layers import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compact vFSMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden\n",
      "[[  1.   2.   3.   4.   5.]\n",
      " [  6.   7.   8.   9.  10.]\n",
      " [ 11.  12.  13.  14.  15.]\n",
      " [ 16.  17.  18.  19.  20.]\n",
      " [ 21.  22.  23.  24.  25.]\n",
      " [ 26.  27.  28.  29.  30.]\n",
      " [ 31.  32.  33.  34.  35.]\n",
      " [ 36.  37.  38.  39.  40.]\n",
      " [ 41.  42.  43.  44.  45.]\n",
      " [ 46.  47.  48.  49.  50.]\n",
      " [ 51.  52.  53.  54.  55.]\n",
      " [ 56.  57.  58.  59.  60.]\n",
      " [ 61.  62.  63.  64.  65.]\n",
      " [ 66.  67.  68.  69.  70.]\n",
      " [ 71.  72.  73.  74.  75.]]\n",
      "filter\n",
      "[[ 0.1  0.2  0.3  0.4  0.5]\n",
      " [ 0.6  0.7  0.8  0.9  1. ]\n",
      " [ 1.1  1.2  1.3  1.4  1.5]\n",
      " [ 1.6  1.7  1.8  1.9  2. ]]\n",
      "position\n",
      "[0 1 2 3 4 5 6 7 0 1 2 3 4 0 1]\n",
      "memory\n",
      "[[   1.     2.     3.     4.     5. ]\n",
      " [   6.1    7.4    8.9   10.6   12.5]\n",
      " [  12.2   14.8   17.8   21.2   25. ]\n",
      " [  21.8   26.7   32.2   38.3   45. ]\n",
      " [  37.4   45.6   54.6   64.4   75. ]\n",
      " [  59.4   69.6   80.6   92.4  105. ]\n",
      " [  81.4   93.6  106.6  120.4  135. ]\n",
      " [ 103.4  117.6  132.6  148.4  165. ]\n",
      " [  41.    42.    43.    44.    45. ]\n",
      " [  50.1   55.4   60.9   66.6   72.5]\n",
      " [  80.2   90.8  101.8  113.2  125. ]\n",
      " [ 133.8  150.7  168.2  186.3  205. ]\n",
      " [ 213.4  237.6  262.6  288.4  315. ]\n",
      " [  66.    67.    68.    69.    70. ]\n",
      " [  77.6   85.4   93.4  101.6  110. ]]\n",
      "dmemory\n",
      "[[ 75.  74.  73.  72.  71.]\n",
      " [ 70.  69.  68.  67.  66.]\n",
      " [ 65.  64.  63.  62.  61.]\n",
      " [ 60.  59.  58.  57.  56.]\n",
      " [ 55.  54.  53.  52.  51.]\n",
      " [ 50.  49.  48.  47.  46.]\n",
      " [ 45.  44.  43.  42.  41.]\n",
      " [ 40.  39.  38.  37.  36.]\n",
      " [ 35.  34.  33.  32.  31.]\n",
      " [ 30.  29.  28.  27.  26.]\n",
      " [ 25.  24.  23.  22.  21.]\n",
      " [ 20.  19.  18.  17.  16.]\n",
      " [ 15.  14.  13.  12.  11.]\n",
      " [ 10.   9.   8.   7.   6.]\n",
      " [  5.   4.   3.   2.   1.]]\n",
      "dhidden\n",
      "[[ 275.   295.2  314.6  333.2  351. ]\n",
      " [ 253.   271.2  288.6  305.2  321. ]\n",
      " [ 231.   247.2  262.6  277.2  291. ]\n",
      " [ 209.   223.2  236.6  249.2  261. ]\n",
      " [ 131.   141.4  151.2  160.4  169. ]\n",
      " [  78.5   85.1   91.3   97.1  102.5]\n",
      " [  49.    51.8   54.4   56.8   59. ]\n",
      " [  40.    39.    38.    37.    36. ]\n",
      " [  99.   103.2  106.6  109.2  111. ]\n",
      " [  61.    63.9   66.2   67.9   69. ]\n",
      " [  36.    37.6   38.8   39.6   40. ]\n",
      " [  21.5   21.8   21.9   21.8   21.5]\n",
      " [  15.    14.    13.    12.    11. ]\n",
      " [  10.5    9.8    8.9    7.8    6.5]\n",
      " [   5.     4.     3.     2.     1. ]]\n",
      "dfilter\n",
      "[[ 10030.  10126.  10198.  10246.  10270.]\n",
      " [  6525.   6672.   6801.   6912.   7005.]\n",
      " [  4010.   4146.   4268.   4376.   4470.]\n",
      " [  2105.   2230.   2345.   2450.   2545.]]\n",
      "dhidden error:  1.2623787284e-09\n",
      "dfilter error:  1.58731882964e-11\n"
     ]
    }
   ],
   "source": [
    "from fsmn import *\n",
    "\n",
    "T, D, N = 15, 5, 4\n",
    "# fake inputs\n",
    "hidden = np.linspace(1, 75, num=T*D).reshape(T, D)\n",
    "filter = np.linspace(0.1, 2.0, num=N*D).reshape(N, D)\n",
    "position = np.array([0,1,2,3,4,5,6,7,0,1,2,3,4,0,1])\n",
    "print \"hidden\\n\", hidden\n",
    "print \"filter\\n\", filter\n",
    "print \"position\\n\", position\n",
    "\n",
    "# forward\n",
    "# also need to check forward implementation\n",
    "memory = compact_vfsmn_memory_forward(hidden, filter, position)\n",
    "print \"memory\\n\", memory\n",
    "\n",
    "# backward\n",
    "# fake output diff\n",
    "dmemory = np.linspace(75, 1, num=T*D).reshape(T, D)\n",
    "print \"dmemory\\n\", dmemory\n",
    "\n",
    "dhidden, dfilter = compact_vfsmn_memory_backward(dmemory, hidden, filter, position)\n",
    "print \"dhidden\\n\", dhidden\n",
    "print \"dfilter\\n\", dfilter\n",
    "\n",
    "# gradient check\n",
    "fhidden = lambda h: compact_vfsmn_memory_forward(h, filter, position)\n",
    "ffilter = lambda f: compact_vfsmn_memory_forward(hidden, f, position)\n",
    "\n",
    "dhidden_num = eval_numerical_gradient_array(fhidden, hidden, dmemory)\n",
    "dfilter_num = eval_numerical_gradient_array(ffilter, filter, dmemory)\n",
    "\n",
    "print 'dhidden error: ', rel_error(dhidden_num, dhidden)\n",
    "print 'dfilter error: ', rel_error(dfilter_num, dfilter)\n",
    "\n",
    "# Just want to know what rel_error(x, y) do\n",
    "# rel_error(x, y): np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "# You can also comment Line:46 in fsmn.py (dhidden[r, c] += dmemory[r, c])\n",
    "# to see the effect of wrong backward implementation\n",
    "#print \"dhidden_num\\n\", dhidden_num\n",
    "#print \"dhidden\\n\", dhidden\n",
    "#print np.abs(dhidden_num - dhidden)\n",
    "#print np.maximum(1e-8, np.abs(dhidden_num) + np.abs(dhidden))\n",
    "#print np.abs(dhidden_num - dhidden) / np.maximum(1e-8, np.abs(dhidden_num) + np.abs(dhidden))\n",
    "#print np.max(np.abs(dhidden_num - dhidden) / np.maximum(1e-8, np.abs(dhidden_num) + np.abs(dhidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
